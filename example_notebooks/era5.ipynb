{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERA5 Analysis Process\n",
    "\n",
    "This Jupyter notebook provides a brief overview of how to use the **geodata** package to download ERA5 data from the [Copernicus Data Store](https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels?tab=overview), create geographic-temporal subsets called cutouts, and use those cutouts to generate standalone datasets for separate analysis.\n",
    "\n",
    "*The following guide assumes you have installed and configured **geodata** and all required dependencies.*\n",
    "\n",
    "*Portions of the walkthrough below are based on [**atlite** documentation here](https://atlite.readthedocs.io/en/latest/introduction.html).  To learn more about the **geodata** package, visit [the geodata repo](https://github.com/east-winds/geodata)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Setup\n",
    "\n",
    "Import the package first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geodata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notifications in **geodata** are implemented using `loggers` from the `logging` library.\n",
    "It is recommended to always launch a logger to get information on what is going on. For debugging, you can use the more verbose `level=logging.DEBUG`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Download and Create Cutout\n",
    "Assuming you have previously created a CDS account and set up the CDS API credentials, you can download ERA5 data from the CDS API as follows.\n",
    "\n",
    "First, define a dataset object for the data you wish to download:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For ERA5, pass geographic bounds in array as follows:\n",
    "## bounds = [North, West, South, East]\n",
    "## Omitting bounds will default to global file of 20+ GB per month\n",
    "DS = geodata.Dataset(module=\"era5\",\n",
    "                     weather_data_config=\"wind_solar_hourly\",\n",
    "                     years=slice(2005, 2005),\n",
    "                     months=slice(1,2),\n",
    "                     bounds=[50, -3, 45, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use `module` to specify the data source. In this example, it is \"era5\".\n",
    "* Use `weather_data_config` to specifiy the dataset.  In this example, hourly data is used, as specified by the `\"wind_solar_hourly\"` value.\n",
    "* Use `years=slice()` and `months=slice()` to specify the years and months for download.  In each parameter, the first value indicates the start period, and the second value the end period.\n",
    "* Use `bounds` to specify the geographic bounds to which you wish to limit your download data.  `bounds` should be set as follows: `bounds = [North, West, South, East]`. Omitting bounds will default to downloading a global file of 20+ GB per month.\n",
    "\n",
    "Use the code block below to begin the download."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a `dataset` object is created, **geodata** performs a check to see if the data specified has already been downloaded by checking for the existence of ERA5 datafiles in the `era5` directory configured in `src/geodata/config.py` (downloaded data is placed into subdirectories by year and then - for daily files - by month, ie `2011/01, 2011/02, 2012/01`, etc).  Monthly files are simply placed in the month's folder.  If downloaded data is found, the `prepared` attribute is set to `True` upon `dataset` object declaration.\n",
    "\n",
    "Accordingly, the snippet below saves you the trouble of accidentally redownloading data if it is already present in the correct subdirectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DS.prepared == False:\n",
    "\tDS.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, in order to use the downloaded ERA5 data with **geodata**, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS.trim_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`trim_variables()` subsets and resaves the downloaded files so that only those variables needed to generate **geodata** outputs are kept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Create Cutout\n",
    "\n",
    "A cutout is a subset of downloaded data based on specified time periods and geographic coordinates.  Cutouts are saved to the cutout directory specified in `src/geodata/config.py` and can be used to generate multiple outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout = geodata.Cutout(name=\"era5-europe-test-2011-02\",\n",
    "                       module=\"era5\",\n",
    "                       weather_data_config=\"wind_solar_hourly\",\n",
    "                       xs=slice(1, 2),\n",
    "                       ys=slice(48, 46),\n",
    "                       years=slice(2005, 2005),\n",
    "                       months=slice(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code creates a cutout for January 2011 for a geographic area corresponding to a portion of Europe. Walking through the parameters:\n",
    "\n",
    "* `name` will be the name of the directory created in the cutouts folder where **geodata** will place the data files corresponding to the cutout.\n",
    "* `module` indicates the source for the data from which the cutout is created.\n",
    "* Use `xs=slice()` and `ys=slice()` to define a geographical range for the cutout. These para\n",
    "* Use `years=slice()` and `months=slice()` to define a temporal range for the cutout. \n",
    "\n",
    "`geodata.Cutout()` only defines the cutout object in memory.  To actually create the cutout files, run `prepare()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running `cutout.prepare()` as above will create the cutout by downloading and then subsetting the ERA5 data.  Accordingly, the above code block could take a while to finish processing.\n",
    "\n",
    "`prepare()` will first perform a check to see if a cutout has already been created at the specified directory, and will exit the download.  creation process if a cutout already exists.  To override this behavior and force a redownload and recalculation of the cutout, run `prepare(overwrite=True)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify the results of the cutout, you can print some attributes to the console as follows.\n",
    "\n",
    "Basic information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout.coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout.meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Generate Outputs\n",
    "\n",
    "**geodata** currently supports the following outputs using ERA5 data from the [Copernicus Data Store](https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels?tab=overview).\n",
    "\n",
    "### Wind\n",
    "* Wind generation time-series (`wind`)\n",
    "* Wind speed time-series (`windspd`)\n",
    "\n",
    "### Solar\n",
    "* Solar photovoltaic generation time-series (`pv`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wind Generation Time-series\n",
    "Convert wind speeds for turbine to wind energy generation using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_wind = geodata.convert.wind(\n",
    "                  cutout, \n",
    "                  turbine='Suzlon_S82_1.5_MW', \n",
    "                  smooth=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going over the parameters:\n",
    "\n",
    "* `cutout` - **string** -  A cutout created by `geodata.Cutout()`\n",
    "* `turbine` - **string or dict** - Name of a turbine known by the reatlas client or a turbineconfig dictionary with the keys 'hub_height' for the hub height and 'V', 'POW' defining the power curve.  For a full list of currently supported turbines, see [the list of Turbines here.](https://github.com/east-winds/geodata/tree/master/geodata/resources/windturbine)\n",
    "* `smooth` - **bool or dict** - If True smooth power curve with a gaussian kernel as determined for the Danish wind fleet to Delta_v = 1.27 and sigma = 2.29. A dict allows to tune these values.\n",
    "\n",
    "*Note* - \n",
    "You can also specify all of the general conversion arguments documented in the `convert_and_aggregate` function (e.g. `var_height='lml'`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convert function returns an xarray dataset, which is an in-memory representation of a NetCDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_wind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert this array to a more conventional dataframe, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wind = ds_wind.to_dataframe(name='wind')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which converts the xarray dataset into a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To output the data to a csv for separate analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wind.to_csv('era5_wind_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wind Speed Density Time-series\n",
    "Extract wind speeds at given height (ms-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_windspd = geodata.convert.windspd(\n",
    "                cutout, \n",
    "                turbine='Vestas_V66_1750kW')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going over the parameters:\n",
    "\n",
    "* `cutout` - **string** -  A cutout created by `geodata.Cutout()`\n",
    "* `**params` - Must have 1 of the following:\n",
    "    - `turbine` - **string or dict** - Name of a turbine known by the reatlas client or a turbineconfig dictionary with the keys 'hub_height' for the hub height and 'V', 'POW' defining the power curve.  For a full list of currently supported turbines, see [the list of Turbines here.](https://github.com/east-winds/geodata/tree/master/geodata/resources/windturbine)\n",
    "    - `hub-height` - **num** - Extrapolation height (m)\n",
    "    \n",
    "*Note* - \n",
    "You can also specify all of the general conversion arguments documented in the `convert_and_aggregate` function (e.g. `var_height='lml'`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convert function returns an xarray dataset, which is an in-memory representation of a NetCDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_windspd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert this array to a more conventional dataframe, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_windspd = ds_windspd.to_dataframe(name='windspd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which converts the xarray dataset into a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_windspd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To output the data to a csv for separate analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_windspd.to_csv('era_windspd_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solar Photovoltaic Generation Time-series\n",
    "\n",
    "Convert downward-shortwave, upward-shortwave radiation flux and ambient temperature into a pv generation time-series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pv = geodata.convert.pv(\n",
    "    cutout, \n",
    "    panel=\"KANENA\", \n",
    "    orientation = \"latitude_optimal\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going over the parameters:\n",
    "\n",
    "* `cutout` - **string** -  A cutout created by `geodata.Cutout()`\n",
    "* `panel` - string - Specify a solar panel type on which to base the calculation.  **geodata** contains an internal solar panel dictionary with keys defining several solar panel characteristics used for the time-series calculation.  For a complete list of included panel types, see [the list of panel types here.](https://github.com/east-winds/geodata/tree/master/geodata/resources/solarpanel)\n",
    "* `orientation` - str, dict or callback - Panel orientation can be chosen from either `latitude_optimal`, a constant orientation such as `{'slope': 0.0,'azimuth': 0.0}`,  or a callback function with the same signature as the callbacks generated by the `geodata.pv.orientation.make_*` functions.\n",
    "* (optional) clearsky_model - string or None - \tEither the `simple` or the `enhanced` Reindl clearsky model. The default choice of None will choose dependending on data availability, since the `enhanced` model also incorporates ambient air temperature and relative humidity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convert function returns an xarray dataset, which is an in-memory representation of a NetCDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert this array to a more conventional dataframe, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pv = ds_pv.to_dataframe(name='pv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which converts the xarray dataset into a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To output the data to a csv for separate analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pv.to_csv('era_pv_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
