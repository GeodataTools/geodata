{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geodata also provides the users with different methods to visualize outputs. \n",
    "\n",
    "To start, import the geodata package with a logger for detailed debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geodata\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also import the `geopandas` and `cartopy` libraries to retrieve and show geospatial [shapefiles](https://en.wikipedia.org/wiki/Shapefile) on the plot, and the `IPython` library to download generated animation as HTML file. These libaries are helpful, but not required to use geodata for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import cartopy.io.shapereader as shpreader\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download example datasets and create cutouts. We will get the hourly aerosol data and the hourly radiation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Download aerosol hourly data\n",
    "aerosol_hourly_data = geodata.Dataset(module=\"merra2\",\n",
    "                                      years=slice(2020, 2020),\n",
    "                                      months=slice(1,12),\n",
    "                                      weather_data_config = \"surface_aerosol_hourly\")\n",
    "\n",
    "#Download radiation hourly data\n",
    "slv_hourly_data = geodata.Dataset(module = \"merra2\", \n",
    "                                  years = slice(2011, 2011),\n",
    "                                  months = slice(1,1),\n",
    "                                  weather_data_config = \"slv_radiation_hourly\")\n",
    "\n",
    "if aerosol_hourly_data.prepared == False:\n",
    "    aerosol_hourly_data.get_data()\n",
    "    \n",
    "#Download radiation hourly data only on 2011/01/01\n",
    "if slv_hourly_data.prepared == False:\n",
    "    slv_hourly_data.get_data(testing = True) \n",
    "\n",
    "#Create northern china aerosol Cutout\n",
    "cutout_pm25 = geodata.Cutout(name=\"beijing19\",\n",
    "                             module=\"merra2\",\n",
    "                             weather_data_config=\"surface_aerosol_hourly\",\n",
    "                             xs=slice(105, 123),\n",
    "                             ys=slice(27, 43),\n",
    "                             years=slice(2019, 2019),\n",
    "                             months=slice(1,12))\n",
    "\n",
    "#Create china solar Cutout\n",
    "cutout_solar = geodata.Cutout(name = \"china-2011-slv-hourly-test\",\n",
    "                        module = \"merra2\",\n",
    "                        weather_data_config = \"slv_radiation_hourly\",\n",
    "                        xs = slice(73, 136), \n",
    "                        ys = slice(18, 54), \n",
    "                        years = slice(2011, 2011), \n",
    "                        months = slice(1,1))\n",
    "\n",
    "cutout_solar.prepare()\n",
    "cutout_pm25.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate pm25 and solar PV Outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pm25 = geodata.convert.pm25(cutout_pm25)\n",
    "ds_solar = geodata.convert.pv(cutout_solar, panel = \"KANEKA\", orientation = \"latitude_optimal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default time series method call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `geodata.plot.time_series` to visualize time series data from the output xarray DataArray, such as `ds_pm25` or `ds_solar`. Its minimal method call find the mean value of all grid cell for every time point in the dataset. For example, with `ds_solar`, we can visualize the spatially aggregated averages AC power over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodata.plot.time_series(ds_solar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial and temporal aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `time_series` method can take in tuple parameters `lat_slice` and `lon_slice` to select grid cells within that range (inclusive). For example, if we want to find the aggregated value for all grid cells between latitude 35 degree and 36 degree, we set `lat_slice` to be (35, 36). The `agg_slice_method` parameter will specify the aggregation method for aggregating grid cells sliced by `lat_slice` or `lon_slice`. By default, `agg_slice_method` is set to mean aggregation. \n",
    "\n",
    "We use the latitude-sliced time-series visualization on the PM2.5 output below. Note that since we have hourly data for the year 2019, we will have 24 * 365 = 8760 timepoints for each hour. However, we can reduce the number of timepoints by taking in a `time_factor` parameter that tells the method how many timepoints to aggregate on. Here, we take 24 * 7 as the `time_factor` so that we will aggregate the data by week, as there are 24 * 7 hours in a week. The `agg_time_method` parameter will specify the aggregation method for time aggregation. By default, `agg_time_method` is set to mean aggregation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, below we visualize the weekly averages of sum of PM2.5 for region within latitude slice (35, 36)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodata.plot.time_series(ds_pm25, \n",
    "                         lat_slice = (35, 36), agg_slice_method = 'sum', \n",
    "                         time_factor = 24 * 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have `lat_slice` or `lon_slice` inputs, and want to plot the time series for every single grid cell without aggregating them, they can specify `agg_slice = False`. This will generate one line for each grid cell.\n",
    "\n",
    "The method also takes in user-defined title with the `title` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodata.plot.time_series(ds_pm25, lat_slice = (35, 36), lon_slice = (110, 111), \n",
    "                         agg_slice = False, \n",
    "                         time_factor = 24 * 7,\n",
    "                         title = \"PM2.5 Time Series - lat(35-36) lon(110-111) weekly average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple coordinate points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use a dictionary of name-coordinate pairs to plot different grid cells. The coordinates value of this `coord_dict` does not have to be exact, as the method can automatically find the grid cell containing the coordinate input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_d = {'Beijing': (30.9, 116.4),\n",
    "           'Shanghai': (31.2, 121.47),\n",
    "           'Xi\\'an': (34.2, 108.9)}\n",
    "\n",
    "geodata.plot.time_series(ds_pm25, coord_dict = coord_d, time_factor = 24 * 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default method call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geodata can plot a spatial heatmap of output values. Since the output is a time-series containing more than 2 dimensions, this method will aggregate the values by mean at different timepoints for each grid cells by default. For example, to see the annual mean PM2.5 in our Cutout region, we use the following method call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodata.plot.heatmap(ds_pm25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add shapefiles to the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `heatmap` method can also take in a `shape` parameter, which takes in a `geopandas` dataframe or series of shape objects. Let us use the province shapes from `cartopy` shape-reader and save the path as `prov_path`. This can also be the path to user-supplied shape files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prov_path = shpreader.natural_earth(resolution='10m', category='cultural', \n",
    "                                    name = 'admin_1_states_provinces')\n",
    "shapes = gpd.read_file(prov_path, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodata.plot.heatmap(ds_pm25, shape = shapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting timepoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do not want the temporally aggregated plot, we can specify the exact time point or its index in the dataArray. In the following method call, `t = 0` uses index to select the first time point in `ds_pm25`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodata.plot.heatmap(ds_pm25, t = 0, shape = shapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take in the exact time point from `ds_pm25` as a string. We can also change the map type from the default `colormesh` to `contour`, and customize the title text like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodata.plot.heatmap(ds_pm25, t = '2019-01-01T00:30:00', \n",
    "                     map_type = 'contour', \n",
    "                     shape = shapes, \n",
    "                     title = 'Contour plot', title_size = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the `heatmap` method on the solar PV output xarray `ds_solar`. Below we select the 7th time point for the `ds_solar` dataArray with the provincial shapes on the same plot.\n",
    "\n",
    "Note that the default map color of the method is `bone_r`, which is not ideal for visualizing solar PV. Therefore, we switch the `cmap` parameter to `Wistia`. You can view a complete list of matplotlib map color [here](https://matplotlib.org/stable/gallery/color/colormap_reference.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodata.plot.heatmap(ds_solar, t = 6, shape = shapes, shape_width = 0.25, shape_color = 'navy',\n",
    "                     map_type = 'contour', cmap = 'Wistia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The drawback of plotting a static heatmap with `heatmap` is that we cannot see the changes over time like the `time_series` plots. However, the `heatmap_animation` method can create an animation of heatmap with time as another dimension in the plot.\n",
    "\n",
    "The parameters of the heatmap_animation is very similar to the ones for `heatmap`. You can use `time_factor` to find aggregated mean or sum. Here, we create the animation with averages for every two hours in the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodata.plot.heatmap_animation(ds_solar, cmap = 'Wistia', \n",
    "                               time_factor = 2, \n",
    "                               shape = shapes, shape_width = 0.25, shape_color = 'navy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The users can save the animation to a file, which requires the `HTML` method from the `IPython` package we imported earlier. It also requires the users to use the Jupyter Notebook in a browser, and have already generated the heatmap animation in the notebook, because `geodata.plot.save_animation` will extract the javascript content string from the animation in the Jupyter Notebook, and use HTML() method to enable the browser to download the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the animation above as a file named `solar_pv_2011_01_01_animation.html`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(geodata.plot.save_animation(\"solar_pv_2011_01_01_animation.html\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
